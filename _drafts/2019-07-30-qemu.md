---
layout: post
title:  Introduction to QEMU
date:   2019-05-31
categories: ["virtualisation"]
---

QEMU is a hypervisor similar to Vmware ES6i, these are known as virtualisers. Virtualiser's enable the ability to run operating systems on top of a host operating system. This can be Windows, OSX, Linux, or it can be the hypervisor itself, which would use a leaner operating system to minimise the amount of resources the host operating system requires.

One advantage of using a hypervisor like QEMU or some other commercial variant, it enables servers running the hypervisor to be used to its fullest extent. From a business viewpoint you would not need to purchase computers and instead use thin clients for access to computing resources.

One notable caveat for QEMU specifically, is not as user friendly as the VMware, VirtualBox. QEMU does not offer a GUI for managing virtual machines, which means a setup has to completed through the terminal only. However, there exists additional packages like virt manager to fill this GUI requirement.

[Introduction to Ivshmem]
Ivshmem is a virtual device that can be attached to the QEMU hypervisor to share a memory region between multiple QEMU processes.

[https://github.com/qemu/qemu/blob/master/docs/specs/ivshmem-spec.txt](https://github.com/qemu/qemu/blob/master/docs/specs/ivshmem-spec.txt)

The ivshmem device is modelled as a PCI device exposing the memory region to the guest as a PCI BAR.

There are two ways for the ivshmem device to use a shared memory object, the first method is on the host directly, and the second method is using a ivshmem server.

The ivshmem server approach offers one additional feature that hosting directly does not have, which is the ivshmem device is able to intruupt its peers and vice versa.

[PCI Bars]

* BAR0 - Holds Device registers
* BAR1 - Holds ivshmem-doorbell
* BAR2 - maps the shared memory object

[Ways of using Ivshmem Device]

* Only BAR2 is needed when shared memory functionility is used, e.g see [http://dpdk.org/browse/memnic](http://dpdk.org/browse/memnic)
* For both shared memory and peer inturrupts functionility, BAR0, 1, 2 are required. Additionally a kernel driver needs to be written to handle interrupts. Also, the ivshmem device will need to be configured for inturrupts.

[Introduction to ivshmem server]
The server listens on a UNIX domain socket (a file-like object)

[PCI drivers]
BUS architectures
kernel functions (API) 